{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d93df50-e4dc-4f06-96d9-fffee8907c5d",
   "metadata": {},
   "source": [
    "## Enhance models for failure type prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e32dd1-f970-4a1d-9a25-368b6f9f06b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridserach for Failure Type (Multiclass)\n",
      "\n",
      " GridSearch for K-Nearest Neighbors\n",
      "   Combinaisons number : 40\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "  Execution time : 5.2s (0.1min)\n",
      " Best macro-recall: 0.7502\n",
      "\n",
      " GridSearch for Neural Network (MLP)\n",
      "   Combinaisons number : 96\n",
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "  Execution time : 3.3s (0.1min)\n",
      " Best macro-recall: 0.8806\n",
      "\n",
      " GridSearch for LightGBM\n",
      "   Combinaisons number : 162\n",
      "   Use of 3000 samples\n",
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "  Execution time : 43.5s (0.7min)\n",
      " Best macro-recall: 0.8343\n",
      "Gridsearch Results - Failure Type (Multiclass)\n",
      "\n",
      " KNN:\n",
      "best parameters : {'clf__metric': 'manhattan', 'clf__n_neighbors': 9, 'clf__p': 1, 'clf__weights': 'distance'}\n",
      "best macro-recall: 0.7502\n",
      "\n",
      " Neural Network (MLP):\n",
      "best parameters :  {'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__batch_size': 32, 'clf__hidden_layer_sizes': (64, 32), 'clf__learning_rate_init': 0.01}\n",
      "best macro-recall: 0.8806\n",
      "\n",
      " LightGBM:\n",
      "best parameters :  {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__n_estimators': 300, 'model__num_leaves': 31, 'model__subsample': 0.8}\n",
      "best macro-recall: 0.8343\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#import models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "\n",
    "#load \n",
    "#we have two versions: original imbalanced data and SMOTE-balanced data\n",
    "\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_train_smote = pd.read_csv('X_train_resampled_failure_type.csv')\n",
    "y_train_smote = pd.read_csv('y_train_resampled_failure_type.csv')['Failure Type']\n",
    "y_train = pd.read_csv('y_train.csv')['Failure Type']\n",
    "\n",
    "print(\"Gridserach for Failure Type (Multiclass)\")\n",
    "\n",
    "\n",
    "def balanced_grid_search(model, params, X, y, model_name, cv_folds=3):\n",
    "    \n",
    "    print(f\"\\n GridSearch for {model_name}\")\n",
    "    print(f\"   Combinaisons number : {np.prod([len(v) for v in params.values()])}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #use a subset if dataset is large to speed up search\n",
    "    sample_size = min(3000, len(X))\n",
    "    if len(X) > sample_size:\n",
    "        from sklearn.utils import resample\n",
    "        X_sample, y_sample = resample(X, y, n_samples=sample_size, \n",
    "                                     random_state=42, stratify=y)\n",
    "        print(f\"   Use of {sample_size} samples\")\n",
    "    else:\n",
    "        X_sample, y_sample = X, y\n",
    "    \n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=params,\n",
    "        cv=cv_folds,\n",
    "        scoring='recall_macro',  \n",
    "        n_jobs=-1,  \n",
    "        verbose=2, \n",
    "        refit=True,\n",
    "        error_score='raise'\n",
    "    )\n",
    "\n",
    "    grid.fit(X_sample, y_sample)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"  Execution time : {elapsed:.1f}s ({elapsed/60:.1f}min)\")\n",
    "    print(f\" Best macro-recall: {grid.best_score_:.4f}\")\n",
    "    \n",
    "    return grid\n",
    "\n",
    "#1)KNN\n",
    "\n",
    "#create pipeline\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "knn_params = {\n",
    "    'clf__n_neighbors': [3, 5, 7, 9, 11], \n",
    "    'clf__weights': ['uniform', 'distance'],   \n",
    "    'clf__metric': ['euclidean', 'manhattan'], \n",
    "    'clf__p': [1, 2]                                                   \n",
    "    \n",
    "}\n",
    "#execute grid search for KNN using SMOTE-balanced data\n",
    "knn_grid = balanced_grid_search(\n",
    "    knn_pipeline, knn_params,\n",
    "    X_train_smote, y_train_smote,\n",
    "    \"K-Nearest Neighbors\",\n",
    "    cv_folds=3\n",
    ")\n",
    "\n",
    "#2)MLP\n",
    "#create pipeline\n",
    "mlp_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', MLPClassifier(random_state=42, max_iter=300, early_stopping=True))\n",
    "])\n",
    "\n",
    "mlp_params = {\n",
    "    'clf__hidden_layer_sizes': [(32,), (64, 32), (128,), (64, 64, 32)], \n",
    "    'clf__activation': ['relu', 'tanh'],                                 \n",
    "    'clf__alpha': [0.0001, 0.001, 0.01],                                \n",
    "    'clf__learning_rate_init': [0.001, 0.01],                          \n",
    "    'clf__batch_size': [32, 64]                                                                              \n",
    "    \n",
    "}\n",
    "#grid search for MLP using SMOTE-balanced data\n",
    "mlp_grid = balanced_grid_search(\n",
    "    mlp_pipeline, mlp_params,\n",
    "    X_train_smote, y_train_smote,\n",
    "    \"Neural Network (MLP)\",\n",
    "    cv_folds=3\n",
    ")\n",
    "\n",
    "\n",
    "#3)LightGBM\n",
    "#create pipeline\n",
    "lgbm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LGBMClassifier(\n",
    "        random_state=42, \n",
    "        verbose=-1, \n",
    "        n_jobs=1,\n",
    "        class_weight='balanced' \n",
    "    ))\n",
    "])\n",
    "\n",
    "lgbm_params = {\n",
    "    'model__n_estimators': [100, 200, 300],      \n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],   \n",
    "    'model__max_depth': [3, 5, 7],               \n",
    "    'model__num_leaves': [31, 50, 100],          \n",
    "    'model__subsample': [0.8, 1.0]               \n",
    "    \n",
    "}\n",
    "#grid search for LightGBM using original imbalanced data\n",
    "lgbm_grid = balanced_grid_search(\n",
    "    lgbm_pipeline, lgbm_params,\n",
    "    X_train, y_train,\n",
    "    \"LightGBM\",\n",
    "    cv_folds=3\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Gridsearch Results - Failure Type (Multiclass)\")\n",
    "\n",
    "print(\"\\n KNN:\")\n",
    "print(f\"best parameters : {knn_grid.best_params_}\")\n",
    "print(f\"best macro-recall: {knn_grid.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\n Neural Network (MLP):\")\n",
    "print(f\"best parameters :  {mlp_grid.best_params_}\")\n",
    "print(f\"best macro-recall: {mlp_grid.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\n LightGBM:\")\n",
    "print(f\"best parameters :  {lgbm_grid.best_params_}\")\n",
    "print(f\"best macro-recall: {lgbm_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca91ea4f-afe0-4eec-b726-5a229b201d9d",
   "metadata": {},
   "source": [
    "### Analysis of gridsearch optimization results : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ebb8c-f9ab-4b69-ac26-7f26cb3e4f95",
   "metadata": {},
   "source": [
    "Optimal Parameters Found for Each Model:\n",
    "\n",
    "1. K-Nearest Neighbors (KNN):\n",
    "\n",
    "Best Recall:  0.9760 avec cv=3 folds\n",
    "Optimal Parameters:\n",
    "\n",
    "n_neighbors: 11   \n",
    "weights: 'distance'    \n",
    "metric: 'manhattan'    \n",
    "p: 1        \n",
    "Performance Insight: KNN maintains its high recall capability with optimized neighborhood parameters.\n",
    "\n",
    "2. Neural Network (MLP):\n",
    "\n",
    "Best Recall: 0.9773 avec cv=3 folds\n",
    "Optimal Parameters:\n",
    "\n",
    "hidden_layer_sizes: (64, 64, 32)    \n",
    "activation: 'tanh'    \n",
    "alpha: 0.001    \n",
    "learning_rate_init: 0.01    \n",
    "batch_size: 32     \n",
    "Performance Insight: Neural Network achieves balanced performance with optimized architecture and regularization, providing both high recall and precision.\n",
    "\n",
    "3. LightGBM:\n",
    "\n",
    "Best Recall: 0.9314 avec cv=3 folds\n",
    "Optimal Parameters:\n",
    "\n",
    "n_estimators: 100    \n",
    "learning_rate: 0.01     \n",
    "max_depth: 3    \n",
    "num_leaves: 31    \n",
    "subsample: 0.8    \n",
    "\n",
    "Performance Insight: With parameter tuning, LightGBM shows improved recall, though still slightly behind KNN and MLP for recall maximization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
